{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnMtQV3CnJFF"
      },
      "source": [
        "#### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "XTCirxlJnIjV"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import csv\n",
        "\n",
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torchvision.transforms as transforms\n",
        "import shutil\n",
        "from torchvision import models\n",
        "# !pip install torchinfo\n",
        "# from torchinfo import summary\n",
        "from torchvision.models import resnet18\n",
        "import math\n",
        "from difflib import SequenceMatcher"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check if we are using gpu or cpu\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "pasc_9SGOjvJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c5b3f80-79c9-40d9-e25c-187b7e697ff6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h7c5_UmjnEa-"
      },
      "source": [
        "#### Data Fetching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9M9ltQaCnEa_"
      },
      "outputs": [],
      "source": [
        "# downloading the iam-handwriting-word-database\n",
        "# which can be found here https://www.kaggle.com/datasets/nibinv23/iam-handwriting-word-database\n",
        "\n",
        "!rm -r ~/.kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!mv ./kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets download -d nibinv23/iam-handwriting-word-database\n",
        "os.mkdir(\"/content/dataset\")\n",
        "!unzip /content/iam-handwriting-word-database.zip -d /content/dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MIN_LABEL_LENGTH = 3\n",
        "MAX_LABEL_LENGTH = 9\n",
        "\n",
        "raw = list()\n",
        "for i, line in enumerate(open(\"/content/dataset/words_new.txt\")):\n",
        "  if i < 19: continue # commented lines - need to ignore them\n",
        "  line_array = line.split(\" \")\n",
        "  path = line_array[0] # gives the path\n",
        "  status = line_array[1] # gives the status of the file\n",
        "  label = line_array[-1] # gives the true label of the image\n",
        "  if status == \"ok\":\n",
        "    label = label[:-1]\n",
        "\n",
        "    #only keep labels that are of length 3 - 9\n",
        "    if len(label) < MIN_LABEL_LENGTH or len(label) > MAX_LABEL_LENGTH: continue\n",
        "\n",
        "    #only keep lables that dont have any special characters\n",
        "    special = any(not c.isalpha() for c in label)\n",
        "    if not special:\n",
        "      example = (path, label)\n",
        "      raw.append(example)"
      ],
      "metadata": {
        "id": "gnAZkaD9Jr2V"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unknown Character: 00\n",
        "# Block Letters: 01-26\n",
        "# Small Letters: 27-52\n",
        "\n",
        "def encode_label(label):\n",
        "  #convert each alphabet to its corresponding ascii value\n",
        "\n",
        "  encoded_label = list()\n",
        "\n",
        "  for character in label:\n",
        "    encoded_character = 0\n",
        "\n",
        "    if character.isalpha():\n",
        "      if character.upper() == character: encoded_character = ord(character) - 64\n",
        "      elif character.lower() == character: encoded_character = ord(character) - 70\n",
        "\n",
        "    else:\n",
        "      print(\"WHOOPS!\")\n",
        "\n",
        "    encoded_label.append(encoded_character)\n",
        "  return encoded_label\n",
        "\n",
        "def decode_label(array):\n",
        "  # exact opposite of encode lables, it converts ascii characters to alphabets\n",
        "  decoded_word = \"\"\n",
        "  for idx in array:\n",
        "    idx = int(idx)\n",
        "    decoded_char = \"&\"\n",
        "    if idx == 0: decoded_char = \"_\"\n",
        "    elif idx <= 26: decoded_char = chr(idx+64)\n",
        "    elif idx <= 52: decoded_char = chr(idx+70)\n",
        "    decoded_word = decoded_word + decoded_char\n",
        "  return decoded_word\n",
        "\n",
        "\n",
        "def pad_label(label):\n",
        "  #pad the labels to the max length of 9 to ensure every lable has the same length\n",
        "  pad_len = MAX_LABEL_LENGTH - len(label)\n",
        "  padding = [0] * pad_len\n",
        "  padded_label = label + padding\n",
        "  return padded_label"
      ],
      "metadata": {
        "id": "sX-aFT5CH-8K"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path, label = raw[0]\n",
        "array = path.split(\"-\")\n",
        "subfolder = array[0] + \"-\" + array[1]\n",
        "base_path = \"/content/dataset/iam_words/words/\"\n",
        "new_path = array[0] + \"/\" + subfolder + \"/\" +path + \".png\"\n",
        "print(\"Path of the example image: \", new_path)\n",
        "\n",
        "encoded = encode_label(label)\n",
        "padded = pad_label(encoded)\n",
        "print(\"Encoded lable of the example image: \", padded)\n",
        "\n",
        "img = cv2.imread(base_path+new_path, cv2.IMREAD_GRAYSCALE)\n",
        "img = cv2.resize(img, (128, 32))\n",
        "print(\"Example Image:\")\n",
        "plt.imshow(img, cmap='gray')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "sS1vMfsVkTvN",
        "outputId": "076a1eb8-7610-4d93-d790-12f5910e7f7d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path of the example image:  a01/a01-000u/a01-000u-00-01.png\n",
            "Encoded lable of the example image:  [13, 15, 22, 5, 0, 0, 0, 0, 0]\n",
            "Example Image:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x78cd283a9c00>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_duplicates(list_of_substrings):\n",
        "  ans = list()\n",
        "\n",
        "  for substring in list_of_substrings:\n",
        "    unique_substring = \"\"\n",
        "    for i in range(len(substring)):\n",
        "      if i==0: unique_substring = unique_substring + substring[i]\n",
        "      elif substring[i-1] != substring[i]: unique_substring = unique_substring + substring[i]\n",
        "    ans.append(unique_substring)\n",
        "\n",
        "  return ans\n",
        "\n",
        "\n",
        "def decode_labels(outputs):\n",
        "  ans = list()\n",
        "\n",
        "  for pred in outputs:\n",
        "    decoded_word = decode_label(pred)\n",
        "    list_of_substrings = decoded_word.split(\"&\")\n",
        "    list_of_unique_substrings = remove_duplicates(list_of_substrings)\n",
        "    decoded_word = \"\".join(list_of_unique_substrings)\n",
        "\n",
        "    for i, char in enumerate(decoded_word):\n",
        "      if char == \"_\": continue\n",
        "      decoded_word = decoded_word[i:]\n",
        "      break\n",
        "    decoded_word = decoded_word.split(\"_\")[0]\n",
        "\n",
        "    ans.append(decoded_word)\n",
        "\n",
        "  return ans\n",
        "\n",
        "def decode_truths(outputs):\n",
        "  ans = list()\n",
        "\n",
        "  for pred in outputs:\n",
        "    decoded_word = decode_label(pred)\n",
        "    decoded_word = decoded_word.split(\"_\")[0]\n",
        "    ans.append(decoded_word)\n",
        "\n",
        "  return ans\n",
        "\n",
        "def similar(a, b):\n",
        "  return SequenceMatcher(None, a, b).ratio()"
      ],
      "metadata": {
        "id": "wvYP9GvVR_Dl"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = list()\n",
        "base_path = \"/content/dataset/iam_words/words/\"\n",
        "\n",
        "for example in raw:\n",
        "  path, label = example\n",
        "  array = path.split(\"-\")\n",
        "  subfolder = array[0] + \"-\" + array[1]\n",
        "  new_path = array[0] + \"/\" + subfolder + \"/\" +path + \".png\"\n",
        "\n",
        "  img = cv2.imread(base_path+new_path, cv2.IMREAD_GRAYSCALE)\n",
        "  if img is None: continue\n",
        "  img = cv2.resize(img, (128, 32))\n",
        "  img = torch.Tensor(img)\n",
        "  img = img.to(device)\n",
        "\n",
        "  encoded = encode_label(label)\n",
        "  padded = pad_label(encoded)\n",
        "  padded = torch.Tensor(padded)\n",
        "  padded = padded.to(device)\n",
        "\n",
        "  dataset.append((img, padded))"
      ],
      "metadata": {
        "id": "sNc01ZcFLBpj"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_length = len(dataset)\n",
        "train_data_length = int(0.90*dataset_length)\n",
        "valid_data_length = int(0.05*dataset_length)\n",
        "test_data_length = dataset_length - train_data_length - valid_data_length\n",
        "\n",
        "train_data, valid_data, test_data = torch.utils.data.random_split(dataset, [train_data_length, valid_data_length, test_data_length])"
      ],
      "metadata": {
        "id": "Y1A4jRVYWoBb"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model Building\n"
      ],
      "metadata": {
        "id": "w4pMbViwc9lV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HandwritingRecogCRNN_new(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(HandwritingRecogCRNN_new, self).__init__()\n",
        "        self.name = \"handwriting_recog_correct\"\n",
        "        self.conv1 = nn.Conv2d(1, 64, 3, padding = 1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(64, 128, 3, padding = 1)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(128, 256, 3, padding = 1)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(256, 256, 3, padding = 1)\n",
        "        self.pool2 = nn.MaxPool2d((2,1))\n",
        "        self.conv5 = nn.Conv2d(256, 512, 3, padding = 1)\n",
        "        self.batch_norm = nn.BatchNorm2d(512)\n",
        "        self.conv6 = nn.Conv2d(512, 512, 3, padding = 1)\n",
        "        self.batch_norm2 = nn.BatchNorm2d(512)\n",
        "        self.conv7 = nn.Conv2d(512, 512, 2)\n",
        "        self.bidirection_lstm = nn.LSTM(input_size = 512, hidden_size = 128, num_layers= 2, bidirectional = True, dropout = 0.2)\n",
        "        self.rnn1 = nn.GRU(input_size=512,\n",
        "                            hidden_size=256,\n",
        "                            bidirectional=True,\n",
        "                            batch_first=True)\n",
        "        self.fc1 = nn.Linear(256, 54)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.float().unsqueeze(dim=1)\n",
        "        # x = x.squeeze(2)\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.pool2(F.relu(self.conv4(x)))\n",
        "        x = F.relu(self.conv5(x))\n",
        "        x = self.batch_norm(x)\n",
        "        x = F.relu(self.conv6(x))\n",
        "        x = self.pool2(self.batch_norm2(x))\n",
        "        x = F.relu(self.conv7(x))\n",
        "        x = x.squeeze()\n",
        "        x = torch.transpose(x, 1, 2)\n",
        "\n",
        "        x, _ = self.bidirection_lstm(x)\n",
        "\n",
        "        # # x = x.view(-1, 10 * 53 * 53)\n",
        "        x = F.log_softmax(self.fc1(x))\n",
        "        return x"
      ],
      "metadata": {
        "id": "YCYHnSytc_yG"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "fgx6Zv25oOwD"
      },
      "outputs": [],
      "source": [
        "# Baseline model that can classify images to different labels\n",
        "class HandwrittenClassifierBaseline(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(HandwrittenClassifierBaseline, self).__init__()\n",
        "        self.name = \"handwritten_classifier\"\n",
        "        self.conv1 = nn.Conv2d(1, 10, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(10, 50, 5)\n",
        "        self.fc1 = nn.Linear(50 * 5 * 29, 30)\n",
        "        self.fc2 = nn.Linear(30, 12)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 50 * 5 * 29)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        x = x.squeeze(1) # Flatten to [batch_size]\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NUNCPJ9nyRj"
      },
      "source": [
        "#### Model Training Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_loader(batch_size=64):\n",
        "  train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
        "  valid_loader = torch.utils.data.DataLoader(dataset=valid_data, batch_size=batch_size, shuffle=True)\n",
        "  testr_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "  return train_loader, valid_loader, testr_loader\n",
        "\n",
        "def get_model_name(name, batch_size, learning_rate, epoch):\n",
        "  path = \"model_{0}_bs{1}_lr{2}_epoch{3}\".format(name, batch_size, learning_rate, epoch)\n",
        "  return path"
      ],
      "metadata": {
        "id": "qe9gH5xOkp0q"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(net, loader, criterion, batch_size=64):\n",
        "    total_loss = 0.0\n",
        "    total_epoch = 0\n",
        "    for i, data in enumerate(loader, 0):\n",
        "        inputs, labels = data\n",
        "\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        outputs = torch.transpose(outputs, 0, 1)\n",
        "        input_lengths = torch.IntTensor([outputs.size(0)] * outputs.size(1))\n",
        "        target_lengths = torch.IntTensor([len(i) for i in labels])\n",
        "        loss = criterion(outputs, labels, input_lengths, target_lengths)\n",
        "        total_loss += loss.item()\n",
        "        total_epoch += len(labels)\n",
        "    loss = float(total_loss) / (i + 1)\n",
        "    return loss\n",
        "\n",
        "def plot_training_curve(path):\n",
        "    train_loss = np.loadtxt(\"{}_train_loss.csv\".format(path))\n",
        "    val_loss = np.loadtxt(\"{}_val_loss.csv\".format(path))\n",
        "    plt.title(\"Train vs Validation Error\")\n",
        "    n = len(train_loss)\n",
        "\n",
        "    plt.title(\"Train vs Validation Loss\")\n",
        "    plt.plot(range(1,n+1), train_loss, label=\"Train\")\n",
        "    plt.plot(range(1,n+1), val_loss, label=\"Validation\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "\n",
        "from torch.nn.modules.loss import SmoothL1Loss\n",
        "\n",
        "def get_accuracy(model, data):\n",
        "    threshold = math.log(0.0005)\n",
        "    correct, total = 0, 0\n",
        "    for images, labels in data:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        output = model(images)\n",
        "        max_val, max_idx = torch.max(output,2)\n",
        "        for j in range(len(output)):\n",
        "          val = max_val[j]\n",
        "          idx = max_idx[j]\n",
        "          for i in range(len(val)):\n",
        "              if val[i] < threshold:\n",
        "                idx[i] = 0\n",
        "          max_idx[j] = idx\n",
        "        prediction = decode_labels(max_idx)\n",
        "\n",
        "        truth = decode_truths(labels)\n",
        "        for i in range(len(prediction)):\n",
        "          # print(\"prediction: \", prediction[i], \"   ground truth: \", truth[i])\n",
        "          correct += similar(prediction[i], truth[i])\n",
        "          total += 1\n",
        "    return correct / total"
      ],
      "metadata": {
        "id": "il3DwPlmkx38"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_pretrained_model(num_epochs, batch_size=64, learning_rate=0.01):\n",
        "  state = torch.load(\"/content/model_handwriting_recog_correct_bs\"+str(batch_size)+\"_lr\"+str(learning_rate)+\"_epoch\"+str(num_epochs-1))\n",
        "  new_model = HandwritingRecogCRNN_new()\n",
        "  new_model.load_state_dict(state)\n",
        "  new_model.to(device)\n",
        "  return new_model"
      ],
      "metadata": {
        "id": "DTbtOQ1-iQ6B"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_net(net, batch_size=64, learning_rate=0.01, num_epochs=30):\n",
        "\n",
        "    torch.manual_seed(1000)\n",
        "    train_loader, val_loader, test_loader = get_data_loader(batch_size)\n",
        "    criterion = nn.CTCLoss(blank=53, zero_infinity=True)\n",
        "    optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)\n",
        "    train_loss = np.zeros(num_epochs)\n",
        "    val_loss = np.zeros(num_epochs)\n",
        "    train_acc, valid_acc = [], []\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        total_train_loss = 0.0\n",
        "        total_epoch = 0\n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "            inputs, labels = data\n",
        "\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(inputs)\n",
        "            outputs = torch.transpose(outputs, 0, 1)\n",
        "\n",
        "            input_lengths = torch.IntTensor([outputs.size(0)] * outputs.size(1))\n",
        "            target_lengths = torch.IntTensor([len(i) for i in labels])\n",
        "            loss = criterion(outputs, labels, input_lengths, target_lengths)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            loss_item = loss.item()\n",
        "            total_train_loss += loss_item\n",
        "            total_epoch += len(labels)\n",
        "\n",
        "        train_loss[epoch] = float(total_train_loss) / (i+1)\n",
        "        val_loss[epoch] = evaluate(net, val_loader, criterion, batch_size)\n",
        "        train_acc.append(get_accuracy(net, train_loader))\n",
        "        valid_acc.append(get_accuracy(net, val_loader))\n",
        "        print((\"Epoch {}: Train loss: {}, Train acc: {} |\"+\n",
        "               \"Validation loss: {}, Validation acc: {}\").format(\n",
        "                   epoch + 1,\n",
        "                   train_loss[epoch],\n",
        "                   train_acc[-1],\n",
        "                  # 0,\n",
        "                   val_loss[epoch],\n",
        "                   valid_acc[-1]\n",
        "                  # 0\n",
        "                  ))\n",
        "        model_path = get_model_name(net.name, batch_size, learning_rate, epoch)\n",
        "        torch.save(net.state_dict(), model_path)\n",
        "        #lr_scheduler.step(train_loss[epoch])\n",
        "\n",
        "    print('Finished Training')\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "    print(\"Total time elapsed: {:.2f} seconds\".format(elapsed_time))\n",
        "    epochs = np.arange(1, num_epochs + 1)\n",
        "    np.savetxt(\"{}_train_loss.csv\".format(model_path), train_loss)\n",
        "    np.savetxt(\"{}_val_loss.csv\".format(model_path), val_loss)"
      ],
      "metadata": {
        "id": "2iTqqgUcd2Jx"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example to start training model:\n",
        "\n",
        "model = HandwritingRecogCRNN_new()\n",
        "model = model.to(device)\n",
        "train_net(net = model, batch_size=64, learning_rate=0.001, num_epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uqsd-XmbYAV",
        "outputId": "04d15ad3-f00f-4992-da7d-bb79e284b1d2"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-899a9c504234>:43: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  x = F.log_softmax(self.fc1(x))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train loss: 11.637594493482844, Train acc: 0.08820082919254592 |Validation loss: 11.273288798332214, Validation acc: 0.08742205711879115\n",
            "Epoch 2: Train loss: 11.494970208303087, Train acc: 0.10110304677249468 |Validation loss: 11.139177751541137, Validation acc: 0.10020101833089747\n",
            "Epoch 3: Train loss: 11.299433347333029, Train acc: 0.13827529351888615 |Validation loss: 10.937200784683228, Validation acc: 0.1395120226188611\n",
            "Epoch 4: Train loss: 11.122697469105438, Train acc: 0.17225352998311824 |Validation loss: 10.788286328315735, Validation acc: 0.17781024533082695\n",
            "Epoch 5: Train loss: 10.992397511108763, Train acc: 0.16734695458548576 |Validation loss: 10.689129376411438, Validation acc: 0.17251632515535276\n",
            "Epoch 6: Train loss: 10.89396577784953, Train acc: 0.1707167547946649 |Validation loss: 10.58661346435547, Validation acc: 0.17347455826676955\n",
            "Epoch 7: Train loss: 10.820117026050657, Train acc: 0.18043366587001664 |Validation loss: 10.53924651145935, Validation acc: 0.17864623894361686\n",
            "Epoch 8: Train loss: 10.76077696353714, Train acc: 0.19134866224520766 |Validation loss: 10.473259973526002, Validation acc: 0.1874856102213995\n",
            "Epoch 9: Train loss: 10.712761522028488, Train acc: 0.21565712568593806 |Validation loss: 10.431081748008728, Validation acc: 0.21314577076929805\n",
            "Epoch 10: Train loss: 10.666979430038804, Train acc: 0.23348951358005435 |Validation loss: 10.374683690071105, Validation acc: 0.23315546146270757\n",
            "Finished Training\n",
            "Total time elapsed: 673.18 seconds\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}